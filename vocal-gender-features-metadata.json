{"@context":{"@language":"en","@vocab":"https://schema.org/","citeAs":"cr:citeAs","column":"cr:column","conformsTo":"dct:conformsTo","cr":"http://mlcommons.org/croissant/","data":{"@id":"cr:data","@type":"@json"},"dataBiases":"cr:dataBiases","dataCollection":"cr:dataCollection","dataType":{"@id":"cr:dataType","@type":"@vocab"},"dct":"http://purl.org/dc/terms/","extract":"cr:extract","field":"cr:field","fileProperty":"cr:fileProperty","fileObject":"cr:fileObject","fileSet":"cr:fileSet","format":"cr:format","includes":"cr:includes","isEnumeration":"cr:isEnumeration","isLiveDataset":"cr:isLiveDataset","jsonPath":"cr:jsonPath","key":"cr:key","md5":"cr:md5","parentField":"cr:parentField","path":"cr:path","personalSensitiveInformation":"cr:personalSensitiveInformation","recordSet":"cr:recordSet","references":"cr:references","regex":"cr:regex","repeated":"cr:repeated","replace":"cr:replace","sc":"https://schema.org/","separator":"cr:separator","source":"cr:source","subField":"cr:subField","transform":"cr:transform","wd":"https://www.wikidata.org/wiki/"},"alternateName":"help identifying male and female voice","conformsTo":"http://mlcommons.org/croissant/1.0","license":{"@type":"sc:CreativeWork","name":"Apache 2.0","url":"https://www.apache.org/licenses/LICENSE-2.0"},"distribution":[{"contentUrl":"https://www.kaggle.com/api/v1/datasets/download/murtadhanajim/vocal-gender-features?datasetVersionNumber=4","contentSize":"3.569 MB","md5":"PgipUAafRDPbFyal5apc4A==","encodingFormat":"application/zip","@id":"archive.zip","@type":"cr:FileObject","name":"archive.zip","description":"Archive containing all the contents of the Gender Recognition by Voice(processed) dataset"},{"contentUrl":"vocal_gender_features_new.csv","containedIn":{"@id":"archive.zip"},"encodingFormat":"text/csv","@id":"vocal_gender_features_new.csv_fileobject","@type":"cr:FileObject","name":"vocal_gender_features_new.csv","description":"csv data"}],"recordSet":[{"field":[{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mean_spectral_centroid"}},"@id":"vocal_gender_features_new.csv/mean_spectral_centroid","@type":"cr:Field","name":"mean_spectral_centroid"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"std_spectral_centroid"}},"@id":"vocal_gender_features_new.csv/std_spectral_centroid","@type":"cr:Field","name":"std_spectral_centroid"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mean_spectral_bandwidth"}},"@id":"vocal_gender_features_new.csv/mean_spectral_bandwidth","@type":"cr:Field","name":"mean_spectral_bandwidth"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"std_spectral_bandwidth"}},"@id":"vocal_gender_features_new.csv/std_spectral_bandwidth","@type":"cr:Field","name":"std_spectral_bandwidth"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mean_spectral_contrast"}},"@id":"vocal_gender_features_new.csv/mean_spectral_contrast","@type":"cr:Field","name":"mean_spectral_contrast"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mean_spectral_flatness"}},"@id":"vocal_gender_features_new.csv/mean_spectral_flatness","@type":"cr:Field","name":"mean_spectral_flatness"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mean_spectral_rolloff"}},"@id":"vocal_gender_features_new.csv/mean_spectral_rolloff","@type":"cr:Field","name":"mean_spectral_rolloff"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"zero_crossing_rate"}},"@id":"vocal_gender_features_new.csv/zero_crossing_rate","@type":"cr:Field","name":"zero_crossing_rate"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"rms_energy"}},"@id":"vocal_gender_features_new.csv/rms_energy","@type":"cr:Field","name":"rms_energy","description":"energy"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mean_pitch"}},"@id":"vocal_gender_features_new.csv/mean_pitch","@type":"cr:Field","name":"mean_pitch"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"min_pitch"}},"@id":"vocal_gender_features_new.csv/min_pitch","@type":"cr:Field","name":"min_pitch"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"max_pitch"}},"@id":"vocal_gender_features_new.csv/max_pitch","@type":"cr:Field","name":"max_pitch"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"std_pitch"}},"@id":"vocal_gender_features_new.csv/std_pitch","@type":"cr:Field","name":"std_pitch"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"spectral_skew"}},"@id":"vocal_gender_features_new.csv/spectral_skew","@type":"cr:Field","name":"spectral_skew"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"spectral_kurtosis"}},"@id":"vocal_gender_features_new.csv/spectral_kurtosis","@type":"cr:Field","name":"spectral_kurtosis"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"energy_entropy"}},"@id":"vocal_gender_features_new.csv/energy_entropy","@type":"cr:Field","name":"energy_entropy"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"log_energy"}},"@id":"vocal_gender_features_new.csv/log_energy","@type":"cr:Field","name":"log_energy"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_1_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_1_mean","@type":"cr:Field","name":"mfcc_1_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_1_std"}},"@id":"vocal_gender_features_new.csv/mfcc_1_std","@type":"cr:Field","name":"mfcc_1_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_2_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_2_mean","@type":"cr:Field","name":"mfcc_2_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_2_std"}},"@id":"vocal_gender_features_new.csv/mfcc_2_std","@type":"cr:Field","name":"mfcc_2_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_3_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_3_mean","@type":"cr:Field","name":"mfcc_3_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_3_std"}},"@id":"vocal_gender_features_new.csv/mfcc_3_std","@type":"cr:Field","name":"mfcc_3_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_4_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_4_mean","@type":"cr:Field","name":"mfcc_4_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_4_std"}},"@id":"vocal_gender_features_new.csv/mfcc_4_std","@type":"cr:Field","name":"mfcc_4_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_5_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_5_mean","@type":"cr:Field","name":"mfcc_5_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_5_std"}},"@id":"vocal_gender_features_new.csv/mfcc_5_std","@type":"cr:Field","name":"mfcc_5_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_6_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_6_mean","@type":"cr:Field","name":"mfcc_6_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_6_std"}},"@id":"vocal_gender_features_new.csv/mfcc_6_std","@type":"cr:Field","name":"mfcc_6_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_7_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_7_mean","@type":"cr:Field","name":"mfcc_7_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_7_std"}},"@id":"vocal_gender_features_new.csv/mfcc_7_std","@type":"cr:Field","name":"mfcc_7_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_8_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_8_mean","@type":"cr:Field","name":"mfcc_8_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_8_std"}},"@id":"vocal_gender_features_new.csv/mfcc_8_std","@type":"cr:Field","name":"mfcc_8_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_9_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_9_mean","@type":"cr:Field","name":"mfcc_9_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_9_std"}},"@id":"vocal_gender_features_new.csv/mfcc_9_std","@type":"cr:Field","name":"mfcc_9_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_10_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_10_mean","@type":"cr:Field","name":"mfcc_10_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_10_std"}},"@id":"vocal_gender_features_new.csv/mfcc_10_std","@type":"cr:Field","name":"mfcc_10_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_11_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_11_mean","@type":"cr:Field","name":"mfcc_11_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_11_std"}},"@id":"vocal_gender_features_new.csv/mfcc_11_std","@type":"cr:Field","name":"mfcc_11_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_12_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_12_mean","@type":"cr:Field","name":"mfcc_12_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_12_std"}},"@id":"vocal_gender_features_new.csv/mfcc_12_std","@type":"cr:Field","name":"mfcc_12_std"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_13_mean"}},"@id":"vocal_gender_features_new.csv/mfcc_13_mean","@type":"cr:Field","name":"mfcc_13_mean"},{"dataType":["sc:Float"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"mfcc_13_std"}},"@id":"vocal_gender_features_new.csv/mfcc_13_std","@type":"cr:Field","name":"mfcc_13_std"},{"dataType":["sc:Integer"],"source":{"fileObject":{"@id":"vocal_gender_features_new.csv_fileobject"},"extract":{"column":"label"}},"@id":"vocal_gender_features_new.csv/label","@type":"cr:Field","name":"label"}],"@id":"vocal_gender_features_new.csv","@type":"cr:RecordSet","name":"vocal_gender_features_new.csv","description":"csv data"}],"version":4,"keywords":["data type \u003E audio","data type \u003E tabular","subject \u003E people and society \u003E people \u003E gender","subject \u003E earth and nature \u003E biology","task \u003E audio-classification","subject \u003E arts and entertainment \u003E music","subject \u003E people and society \u003E social issues and advocacy"],"isAccessibleForFree":true,"includedInDataCatalog":{"@type":"sc:DataCatalog","name":"Kaggle","url":"https://www.kaggle.com"},"creator":{"@type":"sc:Person","name":"murtadha najim","url":"/murtadhanajim","image":"https://storage.googleapis.com/kaggle-avatars/thumbnails/15659108-kg.jpg?t=2024-07-15-15-19-19"},"publisher":{"@type":"sc:Organization","name":"Kaggle","url":"https://www.kaggle.com/organizations/kaggle","image":"https://storage.googleapis.com/kaggle-organizations/4/thumbnail.png"},"thumbnailUrl":"https://storage.googleapis.com/kaggle-datasets-images/6500551/10499064/e124b48a238425dd6ab59a64aeae06c6/dataset-card.jpg?t=2025-01-18-14-00-37","dateModified":"2025-01-18T23:41:34.323","datePublished":"2025-01-17T16:42:01.647","@type":"sc:Dataset","name":"Gender Recognition by Voice(processed)","url":"https://www.kaggle.com/datasets/murtadhanajim/vocal-gender-features/versions/4","description":"This dataset is a cleaned and processed version of [raw audio files for gender classification](https://www.kaggle.com/datasets/murtadhanajim/gender-recognition-by-voiceoriginal). The features were extracted from .wav audio recordings collected in a quiet room with no background noise. The data contains no null or duplicate values, ensuring a high-quality starting point for analysis and modeling.\n\n### Features:\nThe dataset includes the following extracted audio features:\n\n**mean_spectral_centroid:** The average spectral centroid, representing the \u0022center of mass\u0022 of the spectrum, indicating brightness.\n**std_spectral_centroid:** The standard deviation of the spectral centroid, measuring variability in brightness.\n**mean_spectral_bandwidth:** The average width of the spectrum, reflecting how spread out the frequencies are.\n**std_spectral_bandwidth:** The standard deviation of spectral bandwidth, indicating variability in frequency spread.\n**mean_spectral_contrast:** The average difference between peaks and valleys in the spectrum, indicating tonal contrast.\n**mean_spectral_flatness:** The average flatness of the spectrum, measuring the noisiness of the signal.\n**mean_spectral_rolloff:** The average frequency below which a specified percentage of the spectral energy resides, indicating sharpness.\n**zero_crossing_rate:** The rate at which the signal crosses the zero amplitude axis, representing noisiness or percussiveness.\n**rms_energy:** The root mean square energy of the signal, reflecting its loudness.\n**mean_pitch:** The average pitch frequency of the audio.\n**min_pitch:** The minimum pitch frequency.\n**max_pitch:** The maximum pitch frequency.\n**std_pitch:** The standard deviation of pitch frequency, measuring variability in pitch.\n**spectral_skew:** The skewness of the spectral distribution, indicating asymmetry.\n**spectral_kurtosis:** The kurtosis of the spectral distribution, indicating the peakiness of the spectrum.\n**energy_entropy:** The entropy of the signal energy, representing its randomness.\n**log_energy:** The logarithmic energy of the signal, a compressed representation of energy.\n**mfcc_1_mean to mfcc_13_mean:** The mean of the first 13 Mel Frequency Cepstral Coefficients (MFCCs), representing the timbral characteristics of the audio.\n**mfcc_1_std to mfcc_13_std:** The standard deviation of the first 13 MFCCs, indicating variability in timbral features.\n**label:** The target variable indicating the gender male(1) or female(0).\n### Key Information:\n**Clean Data:** The dataset has been thoroughly cleaned and contains no null or duplicate values.\n**Unscaled:** The features are not scaled, allowing users to apply their preferred scaling or normalization techniques.\n**Feature Extraction:** The function used for feature extraction is available in the notebook in the Code section.\n**High Performance:** The data achieved 95%\u002B accuracy using machine learning models such as Random Forest, Extra Trees, and K-Nearest Neighbors (KNN). It also performed exceptionally well with neural networks.\n### Recommendations:\n**Feature Selection:** Avoid using all features in modeling to prevent overfitting. Instead, perform feature selection and choose the most impactful features based on your analysis.\n\nThis processed dataset is a reliable and robust foundation for building high-performing models.\nand if you need any help, you can visit my notebook "}